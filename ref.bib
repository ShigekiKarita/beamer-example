@article{Su2015,
author = {Su, Lichao and Huang, Tianqiang and Yang, Jianmei},
doi = {10.1007/s11042-014-1915-4},
file = {:C$\backslash$:/Users/karita/Documents/Mendeley Desktop/Su, Huang, Yang - 2014 - A video forgery detection algorithm based on compressive sensing.pdf:pdf},
journal = {Multimedia Tools and Applications},
keywords = {compressive sensing,k-svd,passive forensics,video forgery},
mendeley-groups = {VideoForgery/AlSanjary15},
month = sep,
number = {17},
pages = {6641--6656},
title = {{A Video Forgery Detection Algorithm Based on Compressive Sensing}},
volume = {74},
year = {2015}
}

@article{Wang2015,
abstract = {Perceptual image hash has been widely investigated in an attempt to solve the problems of image content authentication and content-based image retrieval. In this paper, we combine statistical analysis methods and visual perception theory to develop a real perceptual image hash method for content authentication. To achieve real perceptual robustness and perceptual sensitivity, the proposed method uses Watson's visual model to extract visually sensitive features that play an important role in the process of humans perceiving image content. We then generate robust perceptual hash code by combining image-block-based features and key-point-based features. The proposed method achieves a tradeoff between perceptual robustness to tolerate content-preserving manipulations and a wide range of geometric distortions and perceptual sensitivity to detect malicious tampering. Furthermore, it has the functionality to detect compromised image regions. Compared with state-of-the-art schemes, the proposed method obtains a better comprehensive performance in content-based image tampering detection and localization.},
author = {Wang, Xiaofeng and Pang, Kemu and Zhou, Xiaorui and Zhou, Yang and Li, Lu and Xue, Jianru},
doi = {10.1109/TIFS.2015.2407698},
file = {:home/karita/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2015 - A Visual Model-Based Perceptual Image Hash for Content Authentication.pdf:pdf},
journal = {IEEE Transactions on Information Forensics and Security},
keywords = {authorisation,content-based retrieval,cryptography,feature extraction,image coding,statistical analysis,visual perception},
mendeley-groups = {VideoForgery/Journal},
month = jul,
number = {7},
pages = {1336--1349},
title = {{A Visual Model-Based Perceptual Image Hash for Content Authentication}},
volume = {10},
year = {2015}
}

@article{Chen2012,
author = {Chen, Richao and Dong, Qiong and Ren, Heng and Fu, Jiaqi},
doi = {10.3923/itj.2012.1456.1462},
file = {:home/karita/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2012 - Video Forgery Detection Based on Non-Subsampled Contourlet Transform and Gradient Information.pdf:pdf},
journal = {Information Technology Journal},
mendeley-groups = {VideoForgery/AlSanjary15},
month = oct,
number = {10},
pages = {1456--1462},
title = {{Video Forgery Detection Based on Non-Subsampled Contourlet Transform and Gradient Information}},
volume = {11},
year = {2012}
}

@incollection{Granados2012,
author = {Granados, Miguel and Kim, Kwang In and Tompkin, James and Kautz, Jan and Theobalt, Christian},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-33718-5_49},
file = {:home/karita/Documents/Mendeley Desktop/Granados et al. - 2012 - Background Inpainting for Videos with Dynamic Objects and a Free-Moving Camera - Lecture Notes in Computer Scie.pdf:pdf},
keywords = {background estimation,free-camera,graph-cuts,image alignment,video completion,video inpainting,video processing},
mendeley-groups = {VideoForgery},
number = {1},
pages = {682--695},
title = {{Background Inpainting for Videos with Dynamic Objects and a Free-Moving Camera}},
volume = {7572 LNCS},
year = {2012}
}

@article{Zhang2009,
abstract = {In the digital multimedia era, it is increasingly important to ensure the integrity and authenticity of the vast volumes of video data. A novel approach is proposed for detecting video forgery based on ghost shadow artifact in this paper. Ghost shadow artifact is usually introduced when moving objects are removed by video inpainting. In our approach, ghost shadow artifact is accurately detected by inconsistencies of the moving foreground segmented from the video frames and the moving track obtained from the accumulative frame differences, thus video forgery is exposed. Experiments show that our approach achieves promising results in video forgery detection.},
author = {Zhang, Jing and Su, Yuting and Zhang, Mingyu},
doi = {10.1145/1631081.1631093},
file = {:home/karita/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Su, Zhang - 2009 - Exposing Digital Video Forgery by Ghost Shadow Artifact.pdf:pdf},
journal = {ACM Multimedia and Security Workshop},
mendeley-groups = {VideoForgery/AlSanjary15},
pages = {49--54},
title = {{Exposing Digital Video Forgery by Ghost Shadow Artifact}},
year = {2009}
}

@article{Murata2012,
abstract = {スパースコーディングは生物の一次視覚野の情報処理を数学的にモデル化したものであり,与えられた画像を少数の基底の線型結合で表現する手法である.観測信号のスパース表現は,工学的にも効率的な情報の保持・伝達,あるいはノイズに対して頑健な情報表現を実現する手法として注目を集めている.本稿では,スパースコーディングを始めとする種々の行列分解手法の数理的側面を,その確率モデルを介して統一的に論じる.また,スパースコーディングの代表的なアルゴリズムと幾つかの応用を紹介する.},
author = {Hino, Hidenori and Murata, Noboru},
file = {:home/karita/Downloads/IPSJ-CVIM12183020.pdf:pdf;:home/karita/Downloads/murata\_sbra2013.pdf:pdf},
journal = {電子情報通信学会技術研究報告. IBISML, 情報論的学習理論と機械学習},
month = aug,
number = {198},
pages = {133--142},
publisher = {一般社団法人電子情報通信学会},
title = {スパース表現の数理とその応用(コンピュータビジョンとパターン認識のための機械学習及び企業ニーズセッション)},
volume = {112},
year = {2012}
}


@article{Newson2014,
abstract = {We propose an automatic video inpainting algorithm which relies on the optimisation of a global, patch-based functional. Our algorithm is able to deal with a variety of challenging situations which naturally arise in video inpainting, such as the correct reconstruction of dynamic textures, multiple moving objects and moving background. Furthermore, we achieve this in an order of magnitude less execution time with respect to the state-of-the-art. We are also able to achieve good quality results on high definition videos. Finally, we provide specific algorithmic details to make implementation of our algorithm as easy as possible. The resulting algorithm requires no segmentation or manual input other than the definition of the inpainting mask, and can deal with a wider variety of situations than is handled by previous work.},
author = {Newson, Alasdair and Almansa, Andr\'{e}s and Fradet, Matthieu and Gousseau, Yann and P\'{e}rez, Patrick},
doi = {10.1137/140954933},
file = {:home/karita/Downloads/Video\_inpainting\_complex\_scenes.pdf:pdf},
issn = {1936-4954},
journal = {SIAM Journal on Imaging Sciences},
keywords = {1,65c20,65k10,68u10,advanced image and video,ams subject classifications,and are also starting,and computer vision world,common,editing techniques are increasingly,in the image processing,introduction,media,moving background,patch-based inpainting,to be used in,video inpainting,video textures},
mendeley-groups = {VideoForgery},
month = jan,
number = {4},
pages = {1993--2019},
title = {{Video Inpainting of Complex Scenes}},
volume = {7},
year = {2014}
}

